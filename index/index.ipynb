{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh.index import create_in\n",
    "from whoosh.fields import *\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "wd = 'downloads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanAutogenSubtitles(subtitles):\n",
    "    line = [item for item in subtitles[2].split('\\n') if item is not ' ']\n",
    "    try:\n",
    "        if(len(line[0].split(' --> ')[1]) > 12):\n",
    "            cleaned = []\n",
    "            for x in subtitles: \n",
    "                line = [item for item in x.split('\\n') if item is not ' ']\n",
    "                line[0] = line[0][:29]\n",
    "                if(len(line) == 2 and len(cleanhtml(line[1])) == len(line[1])):\n",
    "                    cleaned.append(line)\n",
    "            subtitles = cleaned\n",
    "    except:\n",
    "        return subtitles\n",
    "    \n",
    "    return subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accepts data as dictionary\n",
    "def pushCaption(data, user, pwd):\n",
    "    location = 'captions'\n",
    "    url = 'http://127.0.0.1:8000/'+location+'/'\n",
    "    r = requests.post(url, json=data, auth=(user, pwd))\n",
    "    try:\n",
    "        return r.json()\n",
    "    except: \n",
    "        print(r)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(os.walk('.'))[1]\n",
    "\n",
    "subdir_ls = []\n",
    "for subdir in os.walk(wd):\n",
    "    if len(subdir[2]) > 0:\n",
    "        for file in subdir[2]:\n",
    "            subdir_ls += [(subdir[0], file)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23029 of 23029\r"
     ]
    }
   ],
   "source": [
    "#part 0: Create dict of files\n",
    "\n",
    "\"\"\"\n",
    "Data Structure:\n",
    "{\n",
    "    \n",
    "        title: [string],\n",
    "        captions: [txt],\n",
    "        description: [file path],\n",
    "        thumbnail: [file path],\n",
    "        uploader: [string],\n",
    "        id: [string]\n",
    "\n",
    "}\n",
    "\"\"\" \n",
    "\n",
    "file_content_dict = {}\n",
    "for i, file_snippet in enumerate(subdir_ls):\n",
    "    print(str(i+1)+' of '+str(len(subdir_ls)), end='\\r')\n",
    "    \n",
    "    file = file_snippet[1]\n",
    "    if file.split('.')[-1] == 'vtt' or file.split('.')[-1] == 'json':\n",
    "        file_label = \"'\".join(file.split('.')[0:-2])\n",
    "    else:\n",
    "        file_label = \"'\".join(file.split('.')[0:-1])\n",
    "    \n",
    "    try: \n",
    "        file_content_dict[file_label]\n",
    "    except:\n",
    "        file_content_dict[file_label] = {}\n",
    "    \n",
    "    # captions\n",
    "    if file[-4:] == '.vtt':\n",
    "        vtt0 = open(wd+\"/\"+file, \"r\", encoding='utf-8').read()\n",
    "        vtt1 = cleanAutogenSubtitles(vtt0.split('\\n\\n'))\n",
    "        if vtt1 != ['']:\n",
    "            vtt2 = []\n",
    "            for x in vtt1:\n",
    "                if(len(x)>0):\n",
    "                    try:\n",
    "                        tmp = x.split('\\n')\n",
    "                        timepoint = tmp[0].split(' --> ')\n",
    "                        timepoint = timepoint[0] + '\\t' + timepoint[1]   #convert to string\n",
    "#                         label = file + '\\t' + timepoint\n",
    "                        label = timepoint\n",
    "                        vtt2.append((label, ' '.join(tmp[1:]).lower()))\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "            vtt1 = vtt2\n",
    "        file_content_dict[file_label]['captions'] = vtt1\n",
    "        \n",
    "    # thumbnail\n",
    "    elif file[-4:] == '.jpg':\n",
    "        file_content_dict[file_label]['thumbnail'] = file_snippet[0] + '/' + file\n",
    "    \n",
    "    # description\n",
    "    elif file[-12:] == '.description':\n",
    "        file_content_dict[file_label]['description'] = file_snippet[0] + '/' + file\n",
    "    \n",
    "    # additional info\n",
    "    elif file[-10:] == '.info.json':\n",
    "        contents = json.loads(open(wd+\"/\"+file, \"r\", encoding='utf-8').read())\n",
    "        file_content_dict[file_label]['uploader'] = contents['uploader']\n",
    "        file_content_dict[file_label]['id'] = contents['id']\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Schema(title=TEXT(stored=True), path=ID(stored=True), content=TEXT)\n",
    "if not os.path.exists(\"indexdir\"):\n",
    "    os.mkdir(\"indexdir\")\n",
    "ix = create_in(\"indexdir\", schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5813 of 5813\r"
     ]
    }
   ],
   "source": [
    "# writer = ix.writer()\n",
    "length = len(file_content_dict)\n",
    "for i, item in enumerate(file_content_dict):\n",
    "    print(f'{i+1} of {length}', end='\\r')\n",
    "    captions = ''\n",
    "    try:\n",
    "        for caption in file_content_dict[item]['captions']:\n",
    "            captions += caption[1] + ' '\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        data = {\n",
    "            'title': item,\n",
    "            'uploader': file_content_dict[item]['uploader'],\n",
    "            'videoid': file_content_dict[item]['id'],\n",
    "            'thumbnail': file_content_dict[item]['thumbnail'],\n",
    "            'description': file_content_dict[item]['description'],\n",
    "            'captions': captions\n",
    "        }\n",
    "        pushCaption(data, user='admin', pwd='testcase')\n",
    "#         break\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "#     writer.add_document(title=file_label, content=captions)\n",
    "\n",
    "# writer.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open an existing index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whoosh.index as index\n",
    "\n",
    "ix = index.open_dir(\"indexdir\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh.qparser import QueryParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toseconds(timepoint):\n",
    "    tmp = timepoint.split('.')[0].split(':')\n",
    "    hours = int(tmp[0])\n",
    "    minutes = int(tmp[1])\n",
    "    seconds = int(tmp[2])\n",
    "    return str(hours*360 + minutes*60 + seconds)\n",
    "\n",
    "def searchCorpus(q):\n",
    "    with ix.searcher() as searcher:\n",
    "        query = QueryParser('content', ix.schema).parse(q)\n",
    "        results = searcher.search(query, limit=10)\n",
    "        results.fragmenter.charlimit = None\n",
    "        # Show more context before and after\n",
    "        results.fragmenter.surround = 400\n",
    "        for hit in results:\n",
    "            img=mpimg.imread(file_content_dict[hit['title']]['thumbnail'])\n",
    "            imgplot = plt.imshow(img)\n",
    "            plt.show()\n",
    "            print(hit['title'][:-12] + '\\n')\n",
    "\n",
    "            filecontents = ''\n",
    "            for line in file_content_dict[hit['title']]['captions']:\n",
    "                filecontents += '\\n' + line[0] + '\\t' + line[1]\n",
    "            \n",
    "            snippets = hit.highlights('content', text=filecontents, top=5).split('...')\n",
    "            snippets = [cleanhtml(x) for x in snippets]\n",
    "            for snippet in snippets:\n",
    "                surrounding_lines = snippet.split('\\n')[1:-1]\n",
    "                for i, line in enumerate(surrounding_lines):\n",
    "                    tmp = line.split('\\t')\n",
    "                    print('\\t' + tmp[3])\n",
    "                    \n",
    "                    if(i == 0):\n",
    "                        video_id = tmp[0][-18:-7]\n",
    "                        time_start = toseconds(tmp[1])\n",
    "                \n",
    "                try:\n",
    "                    if(len(surrounding_lines) > 0):\n",
    "                        print('\\thttps://app.chimeraeditor.com/player?privacy=private&v=' + video_id + '&t=' + time_start + '\\n')\n",
    "                except:\n",
    "                    continue\n",
    "                \n",
    "            \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search: biology\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Top 10 Results for Term('content', 'biology') runtime=0.0029712489999838>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = input('Search: ')\n",
    "searchCorpus(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
